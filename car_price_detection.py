# -*- coding: utf-8 -*-
"""Car price detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1m--JYsRt3VZZKnSZ9GZ7E2pn7gzM5yxR
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

car = pd.read_csv("/content/car data.csv")
car

print(car['Selling_type'].unique())
print(car['Fuel_Type'].unique())
print(car['Transmission'].unique())
print(car['Owner'].unique())

car.describe()

car.info()

car.duplicated().sum()

car.drop_duplicates(inplace= True)

car.isnull().sum()

#converting the dtype of year
car["Year"]= pd.to_datetime(car["Year"], format = '%Y').dt.year

car["Owner"] = car["Owner"].astype("int32")
car["Driven_kms"] = car["Driven_kms"].astype("int32")

car.info()

car["Year"].unique()

car["Year"].nunique()

#SELECTING IMPORTANT DATA FOR MODEL BUILDING(#FEATURE SELECTION)
car = car.drop(columns= "Car_Name")

### ADDING AGE COLUMN OF CAR
car["current year"]= 2023

car['Age of car']= car["current year"]-car["Year"]

car

car = car.drop(columns= ["current year", "Year"])
car

car = pd.get_dummies(data=car,  drop_first= True)
car

g= ['Fuel_Type_Diesel', 'Fuel_Type_Petrol', 'Selling_type_Individual', 'Transmission_Manual']
car[g]= car[g].astype('int')
car.head(3)

car.corr()

import warnings
warnings.filterwarnings("ignore")
sns.pairplot(car)

sns.heatmap(car.corr(), annot= True, cmap= 'Reds')

# splitting of data
y = car['Selling_Price'] #DEPENDENT VARIABLE AND TARGET
x = car.drop(columns= ['Selling_Price']) # INPUT AND INDEPENDENT DATA
y

x

x['Owner'].unique()

from sklearn.ensemble import ExtraTreesRegressor
model = ExtraTreesRegressor()
model.fit(x,y)

print(model.feature_importances_)

#plot graph of feature importances for better visualization
feat_importances = pd.Series(model.feature_importances_, index=x.columns)
feat_importances.nlargest(5).plot(kind='barh')
plt.show()

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=5)

x_train.shape

x_test.shape

from sklearn.ensemble import RandomForestRegressor

# Creating a RandomForestRegressor without specifying the 'criterion' parameter
regressor = RandomForestRegressor()

# Fit the model
regressor.fit(x_train, y_train)

ypred = regressor.predict(x_test)
ypred

from sklearn.metrics import r2_score
r2_score(y_test, ypred)

from sklearn.model_selection import RandomizedSearchCV
parameters = {
    'n_estimators': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000],
    'criterion': ['squared_error', 'absolute_error', 'poisson', 'friedman_mse'],  # Use valid criterion values
    'max_depth': [10, 20, 30, 40, 50],
    'min_samples_split': [2, 5, 10, 20, 50],
    'min_samples_leaf': [1, 2, 5, 10],
    'max_features': ['auto', 'sqrt', 'log2']
}

parameters

random_cv = RandomizedSearchCV(estimator=regressor, param_distributions=parameters, n_iter=10,
                               scoring ='neg_mean_absolute_error',random_state=42, cv=5, verbose=2, n_jobs=-1)

random_cv.fit(x_train, y_train)

random_cv.best_params_

random_cv.best_score_

predictions=random_cv.predict(x_test)

sns.distplot(y_test-predictions)

plt.scatter(y_test, predictions)

from sklearn import metrics
print('MAE:', metrics.mean_absolute_error(y_test, predictions))
print('MSE:', metrics.mean_squared_error(y_test, predictions))
print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))

x.head(3)

single_ob = np.array([9.5, 15000, 0.0, 5.0, 1.0, 0.0, 0.0, 1.0])
single_ob = single_ob.reshape(1, -1)

regressor.predict(single_ob)

car.head()